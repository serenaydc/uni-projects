This project revolves around the development of a LanguageClassifier model for audio-based language classification. The data loading and processing involve converting input and target data into PyTorch tensors, normalizing them for improved model compatibility and convergence. The proposed model architecture utilizes an LSTM neural network to handle sequential audio data effectively, capturing long-term dependencies and temporal patterns. Experimentation includes hyperparameter tuning and training using stratified k-fold cross-validation. However, the results indicate that the model struggles to generalize well to unseen data, possibly due to overfitting or model architecture limitations. Future work may involve exploring alternative architectures, fine-tuning hyperparameters, data augmentation, and acquiring a more diverse training dataset to enhance generalization capabilities and improve language classification accuracy.