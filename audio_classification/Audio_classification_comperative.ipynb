{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = []\n",
    "validation_data = []\n",
    "testing_data = []\n",
    "split_ratio = 0\n",
    "data_files = []\n",
    "for folder in os.listdir(cwd):\n",
    "    #Finds data folder in directory\n",
    "    correct_folder = folder\n",
    "    testing_correct_folder = correct_folder.isnumeric()\n",
    "    #Ensuring it is a data folder \n",
    "\n",
    "    if testing_correct_folder == False:\n",
    "        #Ensuring it is a data folder; if not, continues to next folder\n",
    "        continue\n",
    "    else:\n",
    "        for file in sorted(os.listdir(folder)):\n",
    "            #for each file in the folder\n",
    "            wav_file = file.split(\".\")[0]\n",
    "            # gets the beginning of the files name\n",
    "            # *This is only possible due to wav & json having same file structure names*\n",
    "            if not file.endswith(\".json\"): continue\n",
    "                #if not a json file continue to next file\n",
    "            filePath = os.path.join(folder, file)\n",
    "            #join directory paths of the folder and current file\n",
    "            wave_file_path = filePath.split(\".\")[0]\n",
    "            with open(filePath, 'r+') as f:\n",
    "                data = json.load(f)\n",
    "                #load json file to extract tags\n",
    "                data_files.append({wave_file_path + \".wav\":data[\"tags\"]})\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplitude Envelope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_envelope = []\n",
    "for items in data_files:\n",
    "    \n",
    "    wav_file = list(items.keys())[0]\n",
    "   \n",
    "    current_wav_file,sr = librosa.load(wav_file)\n",
    "    \n",
    "    sample_duration = 1/sr\n",
    "    #purpose of sample duration is it is neeeded to calculate the duration of the audio signal in seconds\n",
    "    duration = sample_duration * len(current_wav_file)\n",
    "    \n",
    "    # going to have subplot(s) to stack the waveforms for all the different audio signals vertically\n",
    "    \n",
    "    \n",
    "    #calculate amp envelope\n",
    "    #frame_size = 512\n",
    "    frame_size = 1024\n",
    "    hop_length = 512\n",
    "    #hop length is only implmented if it's the case where there is overlapping frames\n",
    "    #given the current frame how many signals we shift to the right for calc max_frame\n",
    "    def amplitude_envelope(signal,frame_size): #hop_length)\n",
    "        amplitude_envelope = []\n",
    "        \n",
    "        #calculating amp_env for each frame\n",
    "        \n",
    "        for i in range(0,len(signal),frame_size): #hop_length)\n",
    "            current_frame_amp_envelope = max(signal[i:i +frame_size])\n",
    "            # slices the signals of the samples for a given frame\n",
    "            amplitude_envelope.append(current_frame_amp_envelope)\n",
    "        \n",
    "        return np.array(amplitude_envelope)\n",
    "    \n",
    "    amp_env_of_current_wave_file = amplitude_envelope(current_wav_file,frame_size) #hop_length)\n",
    "    wave_file_frames = len(amp_env_of_current_wave_file)\n",
    "    #is the number of frame within the current wave file signal\n",
    "    \n",
    "    amp_envelope.append(round(statistics.mean(amp_env_of_current_wave_file),5))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Sqaure Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = []\n",
    "for items in data_files:\n",
    "    wav_file = list(items.keys())[0]\n",
    "   \n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    #extract RMSE with librosa\n",
    "    \n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "   \n",
    "    rms_current_wave_file = librosa.feature.rms(y = current_wav_file[0],frame_length=frame_size,hop_length=hop_len)[0]\n",
    "    RMSE.append(round(statistics.mean((rms_current_wave_file)),5))\n",
    "    #outputs an aggregated result of the rms feature \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossing_rate = []\n",
    "for items in data_files:\n",
    "\n",
    "    wav_file = list(items.keys())[0]\n",
    "    #print(wav_file)\n",
    "   \n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    \n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "    \n",
    "    zero_cross_rate_current_wave_file = librosa.feature.zero_crossing_rate(current_wav_file[0],frame_length=frame_size,hop_length=hop_len)[0]\n",
    "    zero_crossing_rate.append(round(statistics.mean((zero_cross_rate_current_wave_file)),5))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Energy Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BER = []\n",
    "\n",
    "for items in data_files:\n",
    "   \n",
    "    wav_file = list(items.keys())[0]\n",
    "    \n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    \n",
    "    \n",
    "    frame_size = 2848\n",
    "    hop_len = 512\n",
    "    #extract the spectrogram of the wave file\n",
    "    \n",
    "    wave_file_spectrogram = librosa.stft(current_wav_file[0], n_fft=frame_size, hop_length=hop_len)\n",
    "    \n",
    "    #calculating band energy ratio\n",
    "    \n",
    "    def calculating_freq_bin(spectrogram, split_freq, sample_rate):\n",
    "        freq_range = sample_rate/2\n",
    "        #freq range captured within the spectrogram\n",
    "        \n",
    "        freq_delt_per_bin = freq_range / spectrogram.shape[0]\n",
    "        #calculating delta freq between two bins\n",
    "        \n",
    "        split_freq_bin = np.floor(split_freq/ freq_delt_per_bin)\n",
    "        #maps the continous frequnecy onto the closest frequnecy bin availiable \n",
    "        # np.floor is taking a number i.e 10.6 and rounding two to 10 to make an int\n",
    "        return int(split_freq_bin)\n",
    "    \n",
    "    split_freq_bin = calculating_freq_bin(wave_file_spectrogram,2000, current_wav_file[1])\n",
    " \n",
    "    \n",
    "    def band_energy_ratio(spectrogram,split_freq,sample_rate):\n",
    "        split_freq_bin = calculating_freq_bin(wave_file_spectrogram,2000, current_wav_file[1])\n",
    "        \n",
    "        power_spectrogram = np.abs(spectrogram)**2\n",
    "        power_spectrogram = power_spectrogram.T\n",
    "        \n",
    "        band_energy_ratio = []\n",
    "        \n",
    "        for freqs_in_frame in power_spectrogram:\n",
    "            #iterating through frames to get values of freqenies for each frame\n",
    "            #we're calcualting each band energy ratio for each frame\n",
    "            sum_power_lower_freqs = np.sum(freqs_in_frame[:split_freq_bin])\n",
    "            sum_power_high_freqs = np.sum(freqs_in_frame[split_freq_bin:])\n",
    "            \n",
    "            ber_current_frame = sum_power_lower_freqs/sum_power_high_freqs\n",
    "            \n",
    "            band_energy_ratio.append(ber_current_frame)\n",
    "        \n",
    "        return np.array(band_energy_ratio)\n",
    "    \n",
    "    band_energy_ratio_feature = band_energy_ratio(wave_file_spectrogram,2000, current_wav_file[1])\n",
    "    BER.append(round(statistics.mean(band_energy_ratio_feature),3))\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_centroid = []\n",
    "for items in data_files:\n",
    "    wav_file = list(items.keys())[0]\n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "\n",
    "    \n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y = current_wav_file[0], sr= current_wav_file[1])[0]    \n",
    "    spec_centroid.append(round(statistics.mean(spectral_centroid),2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_width = []\n",
    "for items in data_files:\n",
    "  \n",
    "    wav_file = list(items.keys())[0]\n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    \n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "    \n",
    "    band_wid = librosa.feature.spectral_bandwidth(y = current_wav_file[0],sr= current_wav_file[1])[0]\n",
    "    #amounts of freqiecies that are significant around the spectral centroid\n",
    "    band_width.append(round(statistics.mean(band_wid),2))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_spec = []\n",
    "spectrogram = []\n",
    "spectrogram_std = []\n",
    "spec_std = []  \n",
    "spec_mean = []  \n",
    "for items in data_files:\n",
    "  \n",
    "    wav_file = list(items.keys())[0]\n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    \n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "    \n",
    "    #extracting Short time fourier transfrom\n",
    "    st_fourier_transform = librosa.stft(y = current_wav_file[0],n_fft = frame_size,hop_length = hop_len)\n",
    "    \n",
    "    #calculating spectrogram\n",
    "    spec_gram = np.abs(st_fourier_transform)**2\n",
    "    \n",
    "    #Extracting composite value from spectrogram\n",
    "    spectrogram.append(np.mean(spec_gram,axis = 0))\n",
    "       \n",
    "    #Extracting composite value from spectrogram\n",
    "    spectrogram_std.append(np.std(spec_gram,axis = 0))\n",
    " \n",
    "    #calculating log spectrogram\n",
    "    log_spectro = librosa.power_to_db(spec_gram)\n",
    "   \n",
    "      \n",
    "for nums in spectrogram_std:\n",
    "    spec_std.append(np.std(nums))\n",
    "\n",
    "\n",
    "for nums in spectrogram:\n",
    "    spec_mean.append(np.mean(nums))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspectrogram_mean = []\n",
    "melspectrogram_std = []\n",
    "log_mel_spec = [ ]\n",
    "for items in data_files:\n",
    "\n",
    "  \n",
    "    wav_file = list(items.keys())[0]\n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    \n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "    sr = current_wav_file[1]\n",
    "    #mel filter banks\n",
    "    filter_banks = librosa.filters.mel(n_fft = 2048,sr = sr,n_mels = 10)\n",
    "    \n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y = current_wav_file[0],sr=sr,n_fft = 2048,hop_length = hop_len,n_mels = 10)\n",
    "    \n",
    "    melspectrogram_mean.append(np.mean(mel_spectrogram,axis = 0))\n",
    "    \n",
    "    melspectrogram_std.append(np.std(mel_spectrogram,axis = 0))\n",
    "\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "    log_mel_spec.append(log_mel_spectrogram)\n",
    "\n",
    "mel_spec_mean = []\n",
    "for nums in melspectrogram_mean:\n",
    "    mel_spec_mean.append(np.mean(nums))\n",
    "mel_spec_std = []\n",
    "for nums in melspectrogram_std:\n",
    "    mel_spec_std.append(np.std(nums))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel-frequency cepstral coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC = []\n",
    "MFCC_Std = []\n",
    "\n",
    "for items in data_files:\n",
    "  \n",
    "    wav_file = list(items.keys())[0]\n",
    "    current_wav_file = librosa.load(wav_file)\n",
    "    \n",
    "    frame_size = 1024\n",
    "    hop_len = 512\n",
    "    sr = current_wav_file[1]\n",
    "\n",
    "    mel_freq_cepco = librosa.feature.mfcc(y = current_wav_file[0],sr=sr,n_fft = 2048,hop_length = hop_len,n_mels = 10)\n",
    "    \n",
    "    MFCC.append(np.mean(mel_freq_cepco,axis =0))\n",
    "    MFCC_Std.append(np.std(mel_freq_cepco,axis = 0))\n",
    "    \n",
    "    \n",
    "    \n",
    "mfcc_mean = []\n",
    "for nums in MFCC:\n",
    "    mfcc_mean.append(np.mean(nums))\n",
    "mfcc_std = []\n",
    "for nums in MFCC_Std:\n",
    "    mfcc_std.append(np.std(nums))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Existence of Most Prevelant Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = []\n",
    "train = []                \n",
    "voice = []\n",
    "people = []\n",
    "nature = []\n",
    "city = []\n",
    "bird_song = []\n",
    "\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"water\" in words:\n",
    "                water.append(1)\n",
    "            else:\n",
    "                water.append(0)\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"train\" in words:\n",
    "                train.append(1)\n",
    "            else:\n",
    "                train.append(0)\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"voice\" in words:\n",
    "                voice.append(1)\n",
    "            else:\n",
    "                voice.append(0)\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"people\" in words:\n",
    "                people.append(1)\n",
    "            else:\n",
    "                people.append(0)\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"nature\" in words:\n",
    "                nature.append(1)\n",
    "            else:\n",
    "                nature.append(0)\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"city\" in words:\n",
    "                city.append(1)\n",
    "            else:\n",
    "                city.append(0)\n",
    "for items in data_files:\n",
    "    for keylist in list(items.values()):\n",
    "        for words in keylist:\n",
    "            if \"birdsong\" in words:\n",
    "                bird_song.append(1)\n",
    "            else:\n",
    "                bird_song.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_song_count = [bird_song.count(1)]\n",
    "water_count = [water.count(1)]\n",
    "nature_count = [nature.count(1)]\n",
    "city_count = [city.count(1)]\n",
    "voice_count = [voice.count(1)]\n",
    "train_count = [train.count(1)]\n",
    "people_count = [people.count(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Water': water,\n",
    "        'Train': train,\n",
    "        'Nature': nature,\n",
    "        'Voice': voice,\n",
    "        'People': people,\n",
    "        'Birdsong': bird_song,\n",
    "        'City': city}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df1 = df.melt(var_name='Audio Tags', value_name='Count')\n",
    "plt.figure(figsize=(13.7,8.27))\n",
    "ax =sns.countplot(x='Audio Tags', hue='Count', data=df1)\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.bar_label(ax.containers[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio File ID List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_file_list = []\n",
    "for items in list(data_files):\n",
    "    key = list(items.keys())[0]\n",
    "    key = key.split(\"/\")[1]\n",
    "    wave_file_list.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio File Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.DataFrame(list(zip(wave_file_list,spec_mean,spec_std,mel_spec_mean,mel_spec_std,mfcc_mean,mfcc_std,amp_envelope,RMSE,zero_crossing_rate,BER,spec_centroid,band_width,water,train,nature,voice,people,bird_song,city)),\n",
    "               columns =['WaveFiles',\"Spec_mean\" ,\"Spec_std\",\"Mel_Spec_mean\",\"Mel_Spec_std\",\"Mfcc_mean\",\"Mfcc_std\",'Amp_Env',\"RMSE\",\"Zero_Cross\",\"BER\",\"Spec_Cen\",\"Band_Width\",\"Water_Tag\",\"Train_Tag\",\"Nature_Tag\",\"Voice_Tag\",\"People_Tag\",\"Birdsong_Tag\",\"City_Tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =[\"Spec_mean\" ,\"Spec_std\",\"Mel_Spec_mean\",\"Mel_Spec_std\",\"Mfcc_mean\",\"Mfcc_std\",'Amp_Env',\"RMSE\",\"Zero_Cross\",\"BER\",\"Band_Width\"]\n",
    "audio_features = audio_df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "corr = audio_features.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_one = [\"Spec_mean\" ,\"Spec_std\"]\n",
    "feature_set_two = [\"Mel_Spec_mean\",\"Mel_Spec_std\"]\n",
    "feature_set_three = [\"Mfcc_mean\",\"Mfcc_std\"]\n",
    "feature_set_four = [\"Spec_mean\" ,\"Spec_std\",\"Mel_Spec_mean\",\"Mel_Spec_std\"]\n",
    "feature_set_five = [\"Spec_mean\" ,\"Spec_std\",\"Mel_Spec_mean\",\"Mel_Spec_std\",\"Mfcc_mean\",\"Mfcc_std\"]\n",
    "feature_set_six = [\"Spec_mean\" ,\"Spec_std\",\"Mel_Spec_mean\",\"Mel_Spec_std\",\"Mfcc_mean\",'Amp_Env',\"RMSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = audio_df[\"Birdsong_Tag\"]\n",
    "\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Birdsong_Tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grid Search for SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Birdsong_Tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = SVC(C=0.1, gamma=10, kernel='sigmoid')\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = SGDClassifier(alpha=0.001, epsilon=0.01, loss='perceptron', penalty='l1')\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = LogisticRegression(C=100, max_iter=10000, penalty='none', solver='newton-cg')\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"Bird_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_train_prediction_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Water_Tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = np.array(audio_df[\"Water_Tag\"])\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "model_one = DT_GS.best_estimator_.get_params()['dec_tree']\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "model_two = svm_GS.best_estimator_.get_params()['svm']\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "model_three = clf_GS.best_estimator_.get_params()['sgdc']\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "model_four = clf_GS.best_estimator_.get_params()['log']\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Water_Tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = model_one\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = model_two\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = model_three\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = model_four\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"Water_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model_two = bird_train_prediction_df.append(water_train_prediction_df )\n",
    "water_train_prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Train_Tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = np.array(audio_df[\"Train_Tag\"])\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "model_one = DT_GS.best_estimator_.get_params()['dec_tree']\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "model_two = svm_GS.best_estimator_.get_params()['svm']\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "model_three = clf_GS.best_estimator_.get_params()['sgdc']\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "model_four = clf_GS.best_estimator_.get_params()['log']\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Train_Tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = model_one\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = model_two\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = model_three\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = model_four\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"Train_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model_3 = comb_model_two.append(train_train_prediction_df )\n",
    "train_train_prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Nature_Tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = np.array(audio_df[\"Nature_Tag\"])\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "model_one = DT_GS.best_estimator_.get_params()['dec_tree']\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "model_two = svm_GS.best_estimator_.get_params()['svm']\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "model_three = clf_GS.best_estimator_.get_params()['sgdc']\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "model_four = clf_GS.best_estimator_.get_params()['log']\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Nature_Tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = model_one\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = model_two\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = model_three\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = model_four\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"Nature_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model_4 = comb_model_3.append(nature_train_prediction_df)\n",
    "nature_train_prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of People_Tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = np.array(audio_df[\"People_Tag\"])\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "model_one = DT_GS.best_estimator_.get_params()['dec_tree']\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "model_two = svm_GS.best_estimator_.get_params()['svm']\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "model_three = clf_GS.best_estimator_.get_params()['sgdc']\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "model_four = clf_GS.best_estimator_.get_params()['log']\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of People_Tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = model_one\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = model_two\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = model_three\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = model_four\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"People_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model_5 = comb_model_4.append(people_train_prediction_df)\n",
    "people_train_prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of City_tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = np.array(audio_df[\"City_Tag\"])\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "model_one = DT_GS.best_estimator_.get_params()['dec_tree']\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "model_two = svm_GS.best_estimator_.get_params()['svm']\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "model_three = clf_GS.best_estimator_.get_params()['sgdc']\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "model_four = clf_GS.best_estimator_.get_params()['log']\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of City_tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = model_one\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = model_two\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = model_three\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = model_four\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"City_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model_6 = comb_model_5.append(city_train_prediction_df)\n",
    "city_train_prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Binary Classification of Voice_Tag - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = []\n",
    "train_data = []\n",
    "X = audio_df[feature_set_six]\n",
    "y = np.array(audio_df[\"Voice_Tag\"])\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,3,4,5,6,7,8,9,20,50]\n",
    "    \n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    dec_tree__criterion=criterion,\n",
    "                    dec_tree__max_depth=max_depth)\n",
    "\n",
    "DT_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "DT_GS.fit(X_train, y_train)\n",
    "scores = DT_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = DT_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best Criterion:', DT_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', DT_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', DT_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(DT_GS.best_estimator_.get_params()['dec_tree'])\n",
    "model_one = DT_GS.best_estimator_.get_params()['dec_tree']\n",
    "GS_TREE__SCORES = scores\n",
    "GS_TREE__Std = scores_std\n",
    "train_data.append(\"-\")\n",
    "train_data.append(round(max(GS_TREE__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "svm = SVC()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                         ('pca', pca),\n",
    "                           ('svm', svm)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "gamma = [10,100,10000,20000]\n",
    "kernel = ['sigmoid']\n",
    "C =   [0.001, 0.01, 0.1,10,100]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    svm__gamma = gamma,\n",
    "                    svm__C =C,\n",
    "                    svm__kernel = kernel)\n",
    "\n",
    "svm_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "\n",
    "svm_GS.fit(X_train, y_train)\n",
    "scores = svm_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = svm_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', svm_GS.best_estimator_.get_params()['svm__gamma'])\n",
    "print('Best C:', svm_GS.best_estimator_.get_params()['svm__C'])\n",
    "print('Best kernel:', svm_GS.best_estimator_.get_params()['svm__kernel'])\n",
    "print('Best Number Of Components:', svm_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(svm_GS.best_estimator_.get_params()['svm'])\n",
    "model_two = svm_GS.best_estimator_.get_params()['svm']\n",
    "GS_SVM__SCORES = scores\n",
    "GS_SVM__Std = scores_std\n",
    "train_data.append(round(max(GS_SVM__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('sgdc', sgdc)])\n",
    "\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "loss = [\"hinge\",\"log\",\"modified_huber\",\"perceptron\"]\n",
    "epsilon = [.01,.001,.1,.0001,.05]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\"]\n",
    "alpha =  [.00001,.0001,.001,.01,.1]\n",
    "\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    sgdc__loss = loss,\n",
    "                    sgdc__epsilon =epsilon,\n",
    "                    sgdc__penalty = penalty,\n",
    "                    sgdc__alpha = alpha)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "\n",
    "    \n",
    "print('Best gamma:', clf_GS.best_estimator_.get_params()['sgdc__loss'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['sgdc__epsilon'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['sgdc__penalty'])\n",
    "print('Best alpha:', clf_GS.best_estimator_.get_params()['sgdc__alpha'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['sgdc'])\n",
    "model_three = clf_GS.best_estimator_.get_params()['sgdc']\n",
    "GS_SGDC_scores = scores\n",
    "train_data.append(round(max(GS_SGDC_scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "log = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('pca', pca),\n",
    "                           ('log', log)])\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "solver = [\"newton-cg\",\"sag\",\"saga\"]\n",
    "penalty =  [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "C = [100, 10, 1.0, 50, 20,.001,.0001]\n",
    "max_iter = [10000,30000,50000]\n",
    "multi_class = [\"auto\",\"ovr\",\"multinomial\"]\n",
    "    \n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                    log__solver =solver,\n",
    "                    log__penalty=penalty,\n",
    "                    log__C= C,\n",
    "                    log__max_iter = max_iter,\n",
    "                    log__multi_class = multi_class)\n",
    "          \n",
    "clf_GS = GridSearchCV(pipe, parameters,cv = StratifiedKFold(5),scoring='roc_auc',n_jobs = -1)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "scores = clf_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = clf_GS.cv_results_[\"std_test_score\"]  \n",
    "    \n",
    "print('Best solver:', clf_GS.best_estimator_.get_params()['log__solver'])\n",
    "print('Best penalty:', clf_GS.best_estimator_.get_params()['log__penalty'])\n",
    "print('Best Iter:', clf_GS.best_estimator_.get_params()['log__max_iter'])\n",
    "print('Best multi class:', clf_GS.best_estimator_.get_params()['log__multi_class'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['log__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['log'])\n",
    "model_four = clf_GS.best_estimator_.get_params()['log']\n",
    "GS_LOG__SCORES = scores\n",
    "GS_LOG__Std = scores_std\n",
    "GS_LOG__SCORES = [x for x in GS_LOG__SCORES if str(x) != 'nan']\n",
    "train_data.append(round(max(GS_LOG__SCORES),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Voice_Tag - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = model_one\n",
    "dec_tree.fit(X_valid,y_valid)\n",
    "test_score = dec_tree.score(X_test, y_test)\n",
    "y_pred = dec_tree.predict(X_test) \n",
    "predict_data.append(\"-\")\n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "svm = model_two\n",
    "svm.fit(X_valid,y_valid)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "sgdc = model_three\n",
    "sgdc.fit(X_valid,y_valid)\n",
    "test_score = sgdc.score(X_test, y_test)\n",
    "y_pred = sgdc.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))\n",
    "\n",
    "log = model_four\n",
    "log.fit(X_valid,y_valid)\n",
    "test_score = log.score(X_test, y_test)\n",
    "y_pred = log.predict(X_test) \n",
    "predict_data.append(round(roc_auc_score(y_test, y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_train_prediction_df = pd.DataFrame(list(zip(train_data,predict_data)),\n",
    "                                  columns = [\"Training\", \"Prediction\"],\n",
    "                                  index = [\"Voice_Tag\",\"Decision Tree\", \"SVM\", \"SGDC\", \"Log\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eval_df = comb_model_6.append(voice_train_prediction_df)\n",
    "voice_train_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
